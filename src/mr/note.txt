### Lab1 MapReduce

没怎么看论文,课程 note 只讲到了 map 和 reduce, 但是中间其实还有很多步骤, 比如 shuffle,这张图会比较好理解

![asd](https://raw.githubusercontent.com/carlclone/MIT-6.824-LAB-2020/lab3/map_shuffle_reduce.jpg)

Lab1 因为之前写过一个分布式的 crontab ,对 master/worker 的模型还是挺熟悉做起来比较快, 但也只是简单的通过了测试, 用的全局存储 + worker 去轮询 master 的方式, 没有参照论文 ,说起来的话还有很多需要改进的地方

1.可能存在写入文件到一半崩溃的情况,为了避免读到崩溃的文件, 先写入一个tmp file中,完成后再重命名
```
Hints:
worker进程可能需要等待，因为最后一个mapworker没有完成任务，为了避免忙等，可以设置time.sleep()或者条件变量
master需要掌握worker的工作时间，超过一定时间（lab建议10s）后重新调度任务
如果worker出现crash，应当确保它写入的临时文件不会被别的worker读取（因为是残缺文件），所以可以使用ioutil.TempFile创建临时文件并且使用os.Rename自动重命名
```

2.master 奔溃的解决方案? 多 master ?

3.轮询改为 master 主动调度,并监控 worker 状态

4.map 产生的中间文件存在各个 worker 本地,告知 master 获取地址 , 之后 master 把一批中间文件地址告知 reduce worker 去获取和执行

5.一些上层的 map reduce应用代码阅读,尝试编写 (wordCount,索引生成...)




### FailAgree 和 FailNoAgree 的场景

摘抄自https://pdos.csail.mit.edu/6.824/notes/l-raft2.txt

```
how can logs disagree after a crash?
  a leader crashes before sending last AppendEntries to all
    S1: 3
    S2: 3 3
    S3: 3 3
  worse: logs might have different commands in same entry!
    after a series of leader crashes, e.g.
        10 11 12 13  <- log entry #
    S1:  3
    S2:  3  3  4
    S3:  3  3  5

Raft forces agreement by having followers adopt new leader's log
  example:
  S3 is chosen as new leader for term 6
  S3 sends an AppendEntries with entry 13
     prevLogIndex=12
     prevLogTerm=5
  S2 replies false (AppendEntries step 2)
  S3 decrements nextIndex[S2] to 12
  S3 sends AppendEntries w/ entries 12+13, prevLogIndex=11, prevLogTerm=3
  S2 deletes its entry 12 (AppendEntries step 3)
  similar story for S1, but S3 has to back up one farther
  ```


### 资料

[课表](https://pdos.csail.mit.edu/6.824/schedule.html)


某个场景的paper
https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p85.pdf


## 思考记录

加锁意义不明 每一段代码都要能说出为什么存在 意义是什么

加锁的粒度可以很好的参考acid的3个情况 write write. Read write  write read 看你是要避免什么问题来决定锁的粒度 比如两个线程加一 write write问题

并发编程的设计不能直接把语言转换过来 会出现糟糕的设计 实际上任何都是 最好定义好状态机 ，要用上一切最好的流程工具了 画图定义伪代码
